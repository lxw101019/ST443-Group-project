# This is the code for generating confusion matrix/ROC curve point based on given edtimated edge table and true edge table.
#
# Arguments:1. estimate_edge: the TRUE/FALSE table from edgetable.R
#           2. trueEdge: the TRUE/FALSE table from trueEdge.R
#           3. estimate_way: input 'both' or 'either' here. 'both' stands for E_1 estimator. 'either' stands for E_2 estimator.
#
# Retutn: 1.confusion: a list. Use list$TP/FP/FN/TN/TP_rate/FP_rate to get each confusion element or ROC curve point
#
confusion_matrix <- function(estimate_edge, trueEdge, estimate_way){
numOfDims <- nrow(estimate_edge)
confusion <- list(TP = 0,FP = 0,FN = 0,TN = 0,TP_rate = 0,FP_rate = 0)
for (i in seq(numOfDims-1)){
for (j in seq(numOfDims)[seq(numOfDims)>i]){
if (estimate_way == 'either'){
if (trueEdge[i,j] == TRUE){
if (estimate_edge[i,j] == FALSE & estimate_edge[j,i] == FALSE){
confusion$FN <- confusion$FN + 1
} else {
confusion$TP <- confusion$TP + 1
}
} else {
if (estimate_edge[i,j] == FALSE & estimate_edge[j,i] == FALSE){
confusion$TN <- confusion$TN + 1
} else {
confusion$FP <- confusion$FP + 1
}
}
} else if (estimate_way == 'both') {
if (trueEdge[i,j] == TRUE){
if (estimate_edge[i,j] == TRUE & estimate_edge[j,i] == TRUE){
confusion$TP <- confusion$TP + 1
} else {
confusion$FN <- confusion$FN + 1
}
} else {
if (estimate_edge[i,j] == TRUE & estimate_edge[j,i] == TRUE){
confusion$FP <- confusion$FP + 1
} else {
confusion$TN <- confusion$TN + 1
}
}
}
}
}
confusion$TP_rate <- confusion$TP/(confusion$TP + confusion$FN)
confusion$FP_rate <- confusion$FP/(confusion$FP + confusion$TN)
return(confusion)
}
# This is the code for choosing best lambda based using cross validation (select lambda corresponds to lowest MSE)
#
# Arguments:1. data: In this case we input the simulation data
#           2. numOfFolds: 5,10 or loocv. need to type in the exact integer.
#           3. MIN_1SE : Input "MIN" or "1SE".
# Retutn: 1.final: lambda. a number.
cv_best_lambda <- function(data,numOfFolds, MIN_1SE){
library(glmnet)
numOfRows <- nrow(data)
numOfDims <- ncol(data)
lambda.best_list = rep(0,numOfDims)
for (i in seq(numOfDims)){
y <- (data[,i])
x <- (data[,-c(i)])
lasso.train <-cv.glmnet(x, y,type.measure = "mse",nfolds = numOfFolds)
if (MIN_1SE == 'MIN'){
lambda.best_list[i] <-lasso.train$lambda.min
} else if (MIN_1SE == '1SE'){
lambda.best_list[i] <-lasso.train$lambda.1se
}
}
final <- mean(lambda.best_list)
return(final)
}
edge_table <- function(data_set, lambda_choice){
numOfRows <- nrow(data_set)
numOfDims <- ncol(data_set)
edge <- data.frame(matrix(ncol = numOfDims, nrow = numOfDims))
for (i in seq(numOfDims)){
y <- (data_set[,i])
x <- (data_set[,-c(i)])
coeff <- coef(glmnet(x,y, lambda=lambda_choice))
coeff <- as.matrix(coeff)[-c(1)]
coeff <- append(coeff, 1, after= i-1)
edge[i,] <- coeff
}
tf <- data.frame(lapply(edge, function(x) {x!=0}))
colnames(tf) <- seq(numOfDims)
return(tf)
}
# Lin:
# This is the code for choosing best lambda based on the simulation data
#
# Arguments:1. data: In this case we input the simulation data
#
#
# Retutn: 1.final: which is the best lambda,in each case of making X_i as response, there will be a lambda that minimised the test error.
#                  In this case, the best lambda 'final' is the mean of these lambda. Further discussion needed here.
rmse_best_lambda <- function(data){
library(glmnet)
numOfRows <- nrow(data)
numOfDims <- ncol(data)
lambda.best_list = rep(0,numOfDims)
for (i in seq(numOfDims)){
y <- (data[,i])
x <- (data[,-c(i)])
train <-sample(seq(numOfRows), 0.7*numOfRows, replace=FALSE)
lasso.train <-glmnet(x[train,], y[train])
pred.test <-predict(lasso.train, x[-train,])
rmse <-sqrt(apply((y[-train]-pred.test)^2,2,mean))
lambda.best <-lasso.train$lambda[order(rmse)[1]]
lambda.best_list[i] <- lambda.best
}
final <- mean(lambda.best_list)
return(final)
}
# Lin:
# This is the code for choosing best lambda based on the simulation data
#
# Arguments:1. data: In this case we input the simulation data
#
#
# Retutn: 1.final: which is the best lambda,in each case of making X_i as response, there will be a lambda that minimised the test error.
#                  In this case, the best lambda 'final' is the mean of these lambda. Further discussion needed here.
library(glmnet)
ROC_curve <- function(data_set, theta, estimate_way, how_many_lambda_in_roc = 200){
numOfDims <- ncol(data_set)
points <- data.frame(matrix(ncol = 3, nrow = how_many_lambda_in_roc))
# This loop I was trying to calculate the range of lambda that I should use. If you can't find better way to replace it, just use it. It works
max_lambda = 1
min_lambda = 0
for (i in seq(numOfDims)){
y <- (data_set[,i])
x <- (data_set[,-c(i)])
lasso.train <-glmnet(x, y)
if (lasso.train$lambda[1]>max_lambda){
max_lambda <- lasso.train$lambda[1]
}
if (lasso.train$lambda[length(lasso.train$lambda)]<min_lambda){
min_lambda <- lasso.train$lambda[length(lasso.train$lambda)]
}
}
#Lambdas that I am going to use.
lambda_seq <- seq(from = min_lambda, to = max_lambda, length.out= how_many_lambda_in_roc)
#Put it into `points` which is a dataframe we just built
points[,3] <- lambda_seq
true_edge <- true_edge(theta)
for (i in seq(length(lambda_seq))){
print(c('Calculating points:',i))
estimate_edge <- edge_table(data_set, lambda_seq[i])
confusion <- confusion_matrix(estimate_edge, true_edge, estimate_way)
TPR <- confusion$TP_rate
FPR <- confusion$FP_rate
# put them into `points` as well, they will be the coordinates.
points[i,1] <- TPR
points[i,2] <- FPR
}
colnames(points) <- c("TPR","FPR","Lambda")
return(points)
}
true_edge <- function(theta){
numOfDims <- ncol(theta)
theta <- data.frame(theta)
tf <- data.frame(lapply(theta, function(x) {x!=0}))
colnames(tf) <- seq(numOfDims)
return(tf)
}
# Lin:
# This is the code for simulating multivariate gaussian distribution with zero mean and the covariance matrix sigma = theta^-1.
# After discussion, delta now is chosen as minimal as possible.
#
# Arguments:1. number_of_dimensions: the number of variables/features
#           2. how_many_sets_of_data_you_need: As the name said, the number of rows of data do you want to simulate?
#
# Retutn: 1.ls1: a list. list("data" = testdata, "standardtheta" = standard_theta, "theta" = theta)
library(MASS)
library(matrixcalc)
simulation <- function(p, n){
#a generate the lower triangle part of the pxp matrix with 10% to be 0.5 and 90% to be 0.
a <- rbinom(n = p * (p - 1) / 2 , size = 1, prob = 0.1)
a[a == 1] <- 0.5
#B become the B in the sheet. Diagnal is all 0.
B <- matrix(0, p, p)
B[lower.tri(B, diag = FALSE)] <- a
B[upper.tri(B)] <- t(B)[upper.tri(B)]
#Identity matrix
I <- diag(x = 1, p, p)
#In this version, delta will start from 6 and choose as minimal as possible, usually delta = 1 will be chosen.
delta <- 6
is.positive.definite(B+delta*I, tol=0)
while (is.positive.definite(B+delta*I, tol=0)==FALSE){delta <- delta + 1}
#theta
theta = B + delta*I
#standardize the theta
standard_theta <- cov2cor(theta)
#calculate the inverse of theta
covMatrix <- solve(standard_theta)
#generate n random samples from a multivariate gaussian distribution with zero mean and the covariance matrix sigma = theta^-1.
testdata <- mvrnorm(n = n, mu = numeric(p), Sigma = covMatrix, tol = 0, empirical = FALSE, EISPACK = FALSE)
ls1 <-  list("data" = testdata, "standardtheta" = standard_theta, "theta" = theta)
return(ls1)
}
# This is the code for generating confusion matrix/ROC curve point based on given edtimated edge table and true edge table.
#
# Arguments:1. estimate_edge: the TRUE/FALSE table from edgetable.R
#           2. trueEdge: the TRUE/FALSE table from trueEdge.R
#           3. estimate_way: input 'both' or 'either' here. 'both' stands for E_1 estimator. 'either' stands for E_2 estimator.
#
# Retutn: 1.confusion: a list. Use list$TP/FP/FN/TN/TP_rate/FP_rate to get each confusion element or ROC curve point
#
confusion_matrix <- function(estimate_edge, trueEdge, estimate_way){
numOfDims <- nrow(estimate_edge)
confusion <- list(TP = 0,FP = 0,FN = 0,TN = 0,TP_rate = 0,FP_rate = 0)
for (i in seq(numOfDims-1)){
for (j in seq(numOfDims)[seq(numOfDims)>i]){
if (estimate_way == 'either'){
if (trueEdge[i,j] == TRUE){
if (estimate_edge[i,j] == FALSE & estimate_edge[j,i] == FALSE){
confusion$FN <- confusion$FN + 1
} else {
confusion$TP <- confusion$TP + 1
}
} else {
if (estimate_edge[i,j] == FALSE & estimate_edge[j,i] == FALSE){
confusion$TN <- confusion$TN + 1
} else {
confusion$FP <- confusion$FP + 1
}
}
} else if (estimate_way == 'both') {
if (trueEdge[i,j] == TRUE){
if (estimate_edge[i,j] == TRUE & estimate_edge[j,i] == TRUE){
confusion$TP <- confusion$TP + 1
} else {
confusion$FN <- confusion$FN + 1
}
} else {
if (estimate_edge[i,j] == TRUE & estimate_edge[j,i] == TRUE){
confusion$FP <- confusion$FP + 1
} else {
confusion$TN <- confusion$TN + 1
}
}
}
}
}
confusion$TP_rate <- confusion$TP/(confusion$TP + confusion$FN)
confusion$FP_rate <- confusion$FP/(confusion$FP + confusion$TN)
return(confusion)
}
#set.seed(123)
testsample <- simulation(50,100)
# testdata
testdata <- testsample$data
# testtheta
testtheta <-testsample$standardtheta
# 50 times setting for ROC COMPARISON
E1_auc_list = rep(0,50)
E2_auc_list = rep(0,50)
load("~/GitHub/ST443-Group-project/2.1-Node-wise-lasso/LIN/loadallfunction.RData")
# This is the code for simulating multivariate gaussian distribution with zero mean and the covariance matrix sigma = theta^-1.
library("DescTools")
library(ggplot2)
library(MASS)
library(glmnet)
library(matrixcalc)
# 50 times setting for ROC COMPARISON
E1_auc_list = rep(0,50)
E2_auc_list = rep(0,50)
for (i in seq(50)){
testsample <- simulation(175,100)
testdata <- testsample$data
testtheta <-testsample$standardtheta
E1_roc <- ROC_curve(testdata, testtheta,"both",100)
E2_roc <- ROC_curve(testdata, testtheta,"either",100)
E1_auc <- AUC(E1_roc$FPR,E1_roc$TPR,method="step")
E2_auc <- AUC(E2_roc$FPR,E2_roc$TPR,method="step")
E1_auc_list[i] <- E1_auc
E2_auc_list[i] <- E2_auc
}
mean_E1_auc <- mean(E1_auc_list)
mean_E2_auc <- mean(E2_auc_list)
sd_E1_auc <- sd(E1_auc_list)
sd_E2_auc <- sd(E2_auc_list)
summary(E1_auc_list)
setwd("~/GitHub/ST443-Group-project/2.1-Node-wise-lasso/LIN")
load("~/GitHub/ST443-Group-project/2.1-Node-wise-lasso/LIN/loadallfunction.RData")
library("DescTools")
library(ggplot2)
library(MASS)
library(glmnet)
library(matrixcalc)
# 50 times setting for ROC COMPARISON
auc_table <- data.frame(amtrix(ncol = 2, nrow = 50))
# 50 times setting for ROC COMPARISON
auc_table <- data.frame(matrix(ncol = 2, nrow = 50))
colnames(auc_table)<- c('E1_auc','E2_auc')
View(auc_table)
# 50 times setting for ROC COMPARISON
auc_table <- data.frame(matrix(ncol = 2, nrow = 50))
colnames(auc_table)<- c('E1_auc','E2_auc')
for (i in seq(50)){
testsample <- simulation(20,10)
testdata <- testsample$data
testtheta <-testsample$standardtheta
E1_roc <- ROC_curve(testdata, testtheta,"both",100)
E2_roc <- ROC_curve(testdata, testtheta,"either",100)
E1_auc <- AUC(E1_roc$FPR,E1_roc$TPR,method="step")
E2_auc <- AUC(E2_roc$FPR,E2_roc$TPR,method="step")
auc_table[i,1] <- E1_auc
auc_table[i,2] <- E2_auc
}
View(auc_table)
sapply(auc_table, sd, na.rm = TRUE)
sapply(auc_table, mean, na.rm = TRUE)
save.image("~/GitHub/ST443-Group-project/2.1-Node-wise-lasso/LIN/auc_data/20x10.RData")
# 50 times setting for ROC COMPARISON
auc_table <- data.frame(matrix(ncol = 2, nrow = 50))
colnames(auc_table)<- c('E1_auc','E2_auc')
for (i in seq(50)){
testsample <- simulation(20,1000)
testdata <- testsample$data
testtheta <-testsample$standardtheta
E1_roc <- ROC_curve(testdata, testtheta,"both",100)
E2_roc <- ROC_curve(testdata, testtheta,"either",100)
E1_auc <- AUC(E1_roc$FPR,E1_roc$TPR,method="step")
E2_auc <- AUC(E2_roc$FPR,E2_roc$TPR,method="step")
auc_table[i,1] <- E1_auc
auc_table[i,2] <- E2_auc
}
sapply(auc_table, mean, na.rm = TRUE)
sapply(auc_table, sd, na.rm = TRUE)
# 50 times setting for ROC COMPARISON
auc_table <- data.frame(matrix(ncol = 2, nrow = 50))
colnames(auc_table)<- c('E1_auc','E2_auc')
for (i in seq(50)){
testsample <- simulation(20,10000)
testdata <- testsample$data
testtheta <-testsample$standardtheta
E1_roc <- ROC_curve(testdata, testtheta,"both",100)
E2_roc <- ROC_curve(testdata, testtheta,"either",100)
E1_auc <- AUC(E1_roc$FPR,E1_roc$TPR,method="step")
E2_auc <- AUC(E2_roc$FPR,E2_roc$TPR,method="step")
auc_table[i,1] <- E1_auc
auc_table[i,2] <- E2_auc
}
View(auc_table)
View(auc_table)
View(auc_table)
View(auc_table)
View(auc_table)
View(auc_table)
View(auc_table)
View(auc_table)
sapply(auc_table, mean, na.rm = TRUE)
sapply(auc_table, sd, na.rm = TRUE)
save.image("~/GitHub/ST443-Group-project/2.1-Node-wise-lasso/LIN/auc_data/20x10000.RData")
# 50 times setting for ROC COMPARISON
auc_table <- data.frame(matrix(ncol = 2, nrow = 50))
colnames(auc_table)<- c('E1_auc','E2_auc')
for (i in seq(50)){
testsample <- simulation(50,1000)
testdata <- testsample$data
testtheta <-testsample$standardtheta
E1_roc <- ROC_curve(testdata, testtheta,"both",100)
E2_roc <- ROC_curve(testdata, testtheta,"either",100)
E1_auc <- AUC(E1_roc$FPR,E1_roc$TPR,method="step")
E2_auc <- AUC(E2_roc$FPR,E2_roc$TPR,method="step")
auc_table[i,1] <- E1_auc
auc_table[i,2] <- E2_auc
}
sapply(auc_table, mean, na.rm = TRUE)
sapply(auc_table, sd, na.rm = TRUE)
save.image("~/GitHub/ST443-Group-project/2.1-Node-wise-lasso/LIN/auc_data/50x1000.RData")
# 50 times setting for ROC COMPARISON
auc_table <- data.frame(matrix(ncol = 2, nrow = 50))
colnames(auc_table)<- c('E1_auc','E2_auc')
for (i in seq(50)){
testsample <- simulation(100,100)
testdata <- testsample$data
testtheta <-testsample$standardtheta
E1_roc <- ROC_curve(testdata, testtheta,"both",100)
E2_roc <- ROC_curve(testdata, testtheta,"either",100)
E1_auc <- AUC(E1_roc$FPR,E1_roc$TPR,method="step")
E2_auc <- AUC(E2_roc$FPR,E2_roc$TPR,method="step")
auc_table[i,1] <- E1_auc
auc_table[i,2] <- E2_auc
}
sapply(auc_table, mean, na.rm = TRUE)
sapply(auc_table, sd, na.rm = TRUE)
save.image("~/GitHub/ST443-Group-project/2.1-Node-wise-lasso/LIN/auc_data/100x100.RData")
